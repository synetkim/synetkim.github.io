<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-133840577-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
        
          gtag('config', 'UA-133840577-1');
        </script>

        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="">
        <meta name="author" content="">
        <link rel="shortcut icon" href="docs-assets/ico/favicon.png">

        <title>Suyoun Kim contact</title>

        <!-- Bootstrap core CSS -->
        <link href="dist/css/bootstrap.css" rel="stylesheet">

        <!-- Custom styles for this template -->
        <link href="examples/starter-template/starter-template.css" rel="stylesheet">
        <link href="simple_resume_template.css" rel="stylesheet">
    </head>
    <!-- NAVBAR
    ================================================== -->
    <body>
        <div class="navbar-wrapper">
            <div class="container">

                <div class="navbar navbar-inverse navbar-static-top" role="navigation">
                    <div class="container">
                        <div class="navbar-header">
                            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                                <span class="sr-only">Toggle navigation</span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                            </button>
                            <a class="navbar-brand" href="#">Suyoun Kim</a>
                        </div>
                        <div class="navbar-collapse collapse">
                            <ul class="nav navbar-nav">
                                <li class="active"><a href="#">About</a></li>
                            </ul>
                        </div>
                    </div>
                </div>

            </div>
        </div>
        <!--
        ============================================================= -->
        <div class="container">
            <div class="jumbotron">
                <div class="row featurette">
                    <div class="col-md-4">
                        <figure>
                        <img class="img-circle img-responsive" alt="" src="./contents/photo_suyoun.png">
                        </figure>
                    </div>
                    <div class="col-md-8">
                        <h2><b>Suyoun Kim, Ph.D.</b></h2>
                        <h4>
                            Research Scientist<br>
                            Facebook, AI Speech <br> 
                            <b>Contact</b> <br>
                            Email: suyounkim [at] fb [dot] com  <br>
                        </h4>
                        <a class="btn btn-default btn-primary"
                            href="contents/SuyounKim_CV.pdf" download
                            role="button">Download my CV &raquo;</a>  <br>

                        <a target="_blank" href="https://www.linkedin.com/in/suyoun" role="button" class="btn btn-default btn-li"><i class="fa fa-linkedin left"></i> Linkedin</a>
                        <a target="_blank" href="https://github.com/synetkim/" role="button" class="btn btn-default btn-git"><i class="fa fa-github left"></i> Github</a>
                        <a target="_blank"
                            href="https://scholar.google.com/citations?user=zTkuGlEAAAAJ&hl=en"
                            role="button" class="btn btn-default btn-gplus"><i
                                class="fa fa-google-plus left"></i> GoogleScholar</a>
                    </div>
                </div>
            </div>

            <div class="row featurette">
                <div class="col-md-1">
                </div>
                <div class="col-md-10">
                    <p>
                    I am a Research Scientist at 
                    <a class="regular" href="https://research.fb.com/category/natural-language-processing-and-speech/"
                        target="_blank">Facebook, AI Speech</a> 
                    I completed my Ph.D in
                    <a class="regular" href="http://www.ece.cmu.edu"
                        target="_blank">Electrical and Computer Engineering</a> at 
                    <a class="regular" href="http://www.cmu.edu" target="_blank">Carnegie Mellon University</a>, 
                    working with Professors <a class="regular" href="http://users.ece.cmu.edu/~rms/" target="_blank">Richard M. Stern</a>, and 
                    <a class="regular" href="https://www.cs.cmu.edu/~fmetze/interACT/Home.html"
                        target="_blank">Florian Metze</a>.
                    With my research backgrounds in Speech Recognition, Deep Learning, and Machine Learning, most of my research has been concerned with conversational AI and related technologies. 

                    I received M.S. in <a class="regular" href="https://www.lti.cs.cmu.edu"
                        target="_blank">Language Techonologies Institute </a>, <a
                        class="regular" href="http://www.scs.cmu.edu"
                        target="_blank">School of Computer Science</a> at 
                    <a class="regular" href="http://www.cmu.edu" target="_blank">Carnegie Mellon University</a>.
                    </p>
                    <!--
                    #<hr class="featurette-divider">
                    #<h4><font color="red">News</font></h4>
                    #<ul> I am interning at <a target="_blank" href="https://www.microsoft.com/en-us/research/">Microsoft Research (MSR)</a> in this summer 2017, and working with <a target="_blank" href="https://www.microsoft.com/en-us/research/people/mseltzer/">Mike Seltzer</a> in <a target="_blank" href="https://www.microsoft.com/en-us/research/group/speech-dialog-research-group/">"Speech and Dialog Research Group"</a>
                    #</ul> -->

                    <hr class="featurette-divider">
                    <h4>Research Interests</h4>
                    <ul> Speech Recognition, Spoken Dialog System, Deep Learning, Machine Learning
                    </ul>

                    <hr class="featurette-divider">
                    <h4>Ph.D. Dissertation</h4>
                    <ul> End-to-End Speech Recognition on Conversations, Carnegie Mellon University, 2019 <br>
                    Thesis committee: 
                    <a target="_blank" href="https://www.cs.cmu.edu/~fmetze/interACT/Home.html">Florian Metze</a>, 
                    <a target="_blank" href="http://users.ece.cmu.edu/~rms/">Richard M. Stern</a>, 
                    <a target="_blank" href="http://mlsp.cs.cmu.edu/people/bhiksha/">Bhiksha Raj</a>, 
                    <a target="_blank" href="">Michael L. Seltzer</a>, 
                    and 
                    <a target="_blank" href="https://sites.google.com/view/shinjiwatanabe">Shinji Watanabe</a> <br>
	            [<a target="_blank" href="contents/cmu_dissertation_suyounkim.pdf">pdf</a>]
                    </ul>

                    <hr class="featurette-divider">
                    <h4>Paper</h4>
                    <ul>
                        <li><b>Cross-Attention End-to-End ASR for Two-Party Conversations</b><br>
                        <font color="blue">Suyoun Kim</font>, Siddharth Dalmia, Florian Metze <br> 
			<span style="font-style:italic;"> in INTERSPEECH, 2019 </span><br>
                        </li>

                        <li><b>Gated Embeddings in End-to-End Speech Recognition for Conversational-Context Fusion</b><br>
                        <font color="blue">Suyoun Kim</font>, Siddharth Dalmia, Florian Metze <br> 
			<span style="font-style:italic;"> in ACL, 2019 </span><br>
			[<a target="_blank" href="https://arxiv.org/pdf/1906.11604.pdf">paper</a>]
                        </li>

                        <li><b>Acoustic-to-Word Models with Conversational Context Information</b><br>
                        <font color="blue">Suyoun Kim</font>, Florian Metze <br> 
			<span style="font-style:italic;"> in NAACL, 2019 </span><br>
			[<a target="_blank" href="https://www.aclweb.org/anthology/N19-1283">paper</a>]
                        </li>

                        <li><b>Dialog-context aware end-to-end speech recognition</b><br>
                        <font color="blue">Suyoun Kim</font>, Florian Metze <br> 
			<span style="font-style:italic;"> in SLT, 2018 </span><br>
			[<a target="_blank" href="https://arxiv.org/abs/1808.02171">paper</a>]
                        </li>

                        <li><b>Situation Informed End-to-End ASR for CHiME-5 Challenge</b><br>
                        <font color="blue">Suyoun Kim</font>*, Siddharth Dalmia*, Florian Metze <br> 
			<span style="font-style:italic;"> in CHiME Workshop, 2018 </span><br>
			[<a target="_blank" href="http://spandh.dcs.shef.ac.uk/chime_workshop/papers/CHiME_2018_paper_kim.pdf">paper</a>]
                        </li>

                        <li><b>Improved training for online end-to-end speech recognition systems</b><br>
                        <font color="blue">Suyoun Kim</font>, Michael L. Seltzer, Jinyu Li, Rui Zhao <br> 
			<span style="font-style:italic;"> in INTERSPEECH, 2018 </span><br>
			[<a target="_blank" href="https://arxiv.org/abs/1711.02212">paper</a>]
                        </li>

                        <li><b>Towards Language-universal end-to-end speech recognition</b><br>
                        <font color="blue">Suyoun Kim</font>, Michael L. Seltzer <br> 
			<span style="font-style:italic;"> in ICASSP, 2018 [selected to give the oral presentation]</span><br>
			[<a target="_blank" href="https://arxiv.org/abs/1711.02207">paper</a>]
                        </li>

                        <li><b>Hybrid CTC/Attention Architecture for End-to-End Speech Recognition</b><br>
                        Shinji Watanabe, Takaaki Hori, <font color="blue">Suyoun Kim</font>, John R Hershey, Tomoki Hayashi <br> 
			<span style="font-style:italic;"> IEEE Journal of Selected Topics in Signal Processing, 2017 </span><br>
                        [<a target="_blank" href="http://ieeexplore.ieee.org/abstract/document/8068205/">paper</a>]
                        </li>

                        <li><b>End-to-End Speech Recognition with Auditory Attention for Multi-Microphone Distance Speech Recognition</b><br>
                        <font color="blue">Suyoun Kim</font>, Ian Lane,<br> <span style="font-style:
                        italic;">in INTERSPEECH, 2017 </span><br>
                        [<a target="_blank" href="http://www.isca-speech.org/archive/Interspeech_2017/pdfs/1536.PDF">paper</a>]
                        </li>

                        <li><b>Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning</b><br>
                        <font color="blue">Suyoun Kim</font>, Takaaki Hori,
                        Shinji Watanabe,<br> <span style="font-style:
                        italic;">in ICASSP, 2017 [selected to give the oral presentation]</span><br>
                        [<a target="_blank" href="https://arxiv.org/abs/1609.06773">paper</a>]
                        </li>

                        <li><b>Multi-Channel Speech Recognition: LSTMs All the Way Through</b><br>
                        Hakan Erdogan, Tomoki Hayashi, John R. Hershey, Takaaki Hori, Chiori Hori, Wei-Ning Hsu, 
                        <font color="blue">Suyoun Kim</font>, Jonathan Le Roux, Zhong Meng, and Shinji Watanabe <br>
                        <span style="font-style:
                        italic;">in CHiME Workshop, 2016 </span><br>
                        [<a target="_blank" href="https://pdfs.semanticscholar.org/ef2e/2f3a847667000b591c8708b543eaf259113b.pdf">paper</a>]
                        </li>

                        <li><b>Recurrent Models for Auditory Attention in Multi-Microphone Distant Speech Recognition</b><br>
                        <font color="blue">Suyoun Kim</font>, Ian Lane,<br> <span style="font-style: italic;">in INTERSPEECH, 2016</span><br>
                        [<a target="_blank" href="http://www.isca-speech.org/archive/Interspeech_2016/pdfs/0326.PDF">paper</a>]
                        </li>

                        <li><b>Environmental Noise Embeddings for Robust Speech Recognition</b><br>
                        <font color="blue">Suyoun Kim</font>, Bhiksha Raj, Ian Lane,<br> <span style="font-style: italic;">in arXiv, 2016</span><br>
                        [<a target="_blank" href="https://arxiv.org/abs/1601.02553">paper</a>]
                        </li>

                        <li><b>Recurrent Models for Auditory Attention in Multi-Microphone Distant Speech Recognition (earlier version)</b><br>
                        <font color="blue">Suyoun Kim</font>, Ian Lane,<br> <span style="font-style: italic;">in ICLR workshop, 2016</span><br>
                        [<a target="_blank" href="https://arxiv.org/abs/1511.06407">paper</a>]
                        </li>

                        <li><b>Multimodal Transfer Deep Learning with an Application in Audio-Visual Recognition</b><br>
                        Seungwhan Moon, <font color="blue">Suyoun Kim</font>,
                        Haohan Wang,<br> <span style="font-style: italic;">in
                        NIPS workshop, 2015</span><br>
                        [<a target="_blank" href="https://arxiv.org/abs/1412.3121">paper</a>]
                        </li>

                        <li><b>Impact of nano-scale through-silicon vias on the quality of today and future 3D IC designs</b><br>
                        Dae Hyun Kim, <font color="blue">Suyoun Kim</font>, Sung Kyu Lim, <br> <span style="font-style: italic;">Proceedings of the System Level Interconnect Prediction Workshop. IEEE Press, 2011</span><br>
                        [<a target="_blank"
                            href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6135435">paper</a>]
                        </li>
                    </ul>
                    <hr class="featurette-divider">
                    <h4>Patent</h4>
                    <ul>
                        <li><b>Attention-based Neural Networks for Multi-Microphone Speech Recognition,</b> Provisional Patent Application 2016-127
                        </li>
                    </ul>
                    <hr class="featurette-divider">
                    <h4>Professional Experience</h4>
                    <ul>
                        <li><b><a target="_blank" href="https://www.microsoft.com/en-us/research/group/speech-dialog-research-group/">Microsoft Research (MSR)</a></b>, Speech and Dialog Research Group, Summer 2017 <br>
                            Research Intern, responsible for research on speech recognition
                        </li>
                        <li><b><a target="_blank" href="https://www.ece.cmu.edu">Carnegie Mellon University</a></b>, Electrical and Computer Engineering, 2014 - Present <br>
                            Research Assistant, responsible for research on speech recognition
                        </li>
                        <li><b><a target="_blank" href="http://www.merl.com/">Mitsubishi Electric Research Laboratories (MERL)</a></b>, Speech & Audio Lab., Summer 2016 <br>
                            Research Intern, responsible for research on End-to-end speech recognition system <br>
                            Collaboration with Shinji Watanabe, and Takaaki Hori
                        </li>
                        <li><b><a target="_blank" href="https://lti.cs.cmu.edu/">Carnegie Mellon University</a></b>, School of Computer Science, LTI, 2012 - 2014 <br>
                            Research Assistant, responsible for research on computational biology, protein protein interaction, and drug repositioning 
                        </li>
                        <li><b><a target="_blank" href="http://www.samsung.com/us/">Samsung Electronics</a></b>, Visual Display Division, 2005 - 2012 <br>
                            Software Engineer, responsible for development of Internet Protocol Set-top Box software on embedded linux system
                        </li>
                        <li><b><a target="_blank" href="http://www.secmem.org/">Samsung Software Membership</a></b>, 2004 - 2005 <br>
                        </li>
                    </ul>

                    <hr class="featurette-divider">
                    <h4>Awards and Honors</h4>
                    <ul>
                        <li><b><a target="_blank" href="https://www.cs.cmu.edu/cmlh-cfp/fellows"> Center for Machine Learning and Health (CMLH) Fellowship in Digital Health </a></b>, 2017 - 2018 <br>
                        </li>
                        <li> Samsung Graduate Fellowship, 2010 - 2011 <br>
                             Academic Training Program
                        </li>
                    </ul>

                    <hr class="featurette-divider">
                    <h4>Teaching</h4>
                    <ul>
                        <li> Spring 2018, 
                        <a href="https://www.ece.cmu.edu/courses/items/18752.html">Estimation, Detection and Learning </a></li> 
                        Teaching Assistant for Prof. Rohit Negi 
                        </li>
                        <li> Fall 2015, 
                        <a href="https://www.ece.cmu.edu/courses/items/18781.html">Speech Recognition and Understanding </a></li> 
                        Teaching Assistant for Prof. Ian Lane, and Prof. Florian Metze
                        </li>
                    </ul>

                    <hr class="featurette-divider">
                    <h4>Courses</h4>
                    <ul>
                    <li> Spring 2016
                    <a class="regular"
                        href="https://www.ece.cmu.edu/~ece491/"
                        target="_blank">
                        Fundamentals of Signal Processing </a> <br>
                    </li>
                    <li> Fall 2015
                    <a class="regular"
                        href="http://www.stat.cmu.edu/~ryantibs/convexopt/"
                        target="_blank">
                        Convex Optimization </a> <br>
                    </li>
                    <li> Fall 2014
                    <a class="regular" href="http://deeplearning.cs.cmu.edu"
                        target="_blank">
                        Deep Learning </a> <br>
                    </li>
                    <li> Fall 2014
                    <a class="regular"
                        href="https://sites.google.com/a/is.cs.cmu.edu/lti-speech-classes/11-751-speech-recognition-and-under"
                        target="_blank">
                        Speech Recognition and Understanding </a> <br>
                    </li>
                    <li> Spring 2014
                    <a class="regular"
                        href="http://boston.lti.cs.cmu.edu/classes/11-741/"
                        target="_blank">
                        Information Retrieval </a> <br>
                    </li>
                    <li> Fall 2013
                    <a class="regular" href="http://mlsp.cs.cmu.edu/courses/fall2013/"
                        target="_blank">
                        Machine Learning for Signal Processing </a> <br>
                    </li>
                    <li> Fall 2013
                    <a class="regular"
                        href="http://demo.clab.cs.cmu.edu/fa2013-11711/index.php/Main_Page"
                        target="_blank">
                        Algorithms for NLP </a> <br>
                    </li>
                    <li> Spring 2013
                    <a class="regular" href="http://www.cs.cmu.edu/~roni/11761/"
                        target="_blank">
                        Language and Statistics </a> <br>
                    </li>
                    <li> Spring 2013
                    <a class="regular" href="http://www.cs.cmu.edu/~ehn/seit.html"
                        target="_blank">
                        Software Engineering for Information Systems 2 </a> <br>
                    </li>
                    <li> Fall 2012
                    <a class="regular" href="http://www.cs.cmu.edu/~tom/10601_fall2012/"
                        target="_blank">
                        Machine Learning 10601 </a> <br>
                    </li>
                    <li> Fall 2012
                    <a class="regular" href="http://www.cs.cmu.edu/~ehn/seit.html"
                        target="_blank">
                        Software Engineering for Information Systems </a> <br>
                    </li>

                    </ul>

                </div> <!-- cols -->
                <div class="col-md-1">
                </div>
            </div> <!-- row -->
            <hr class="featurette-divider">
            <footer>
            <p class="pull-right"><a href="#">Back to top</a></p>
            <p>&copy; Suyoun Kim 2016 &middot; <a href="#">Privacy</a> &middot; <a href="#">Terms</a></p>
            </footer>

        </div>
    </div><!-- /.container -->
</div>

<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
<script src="dist/js/bootstrap.min.js"></script>
<script src="docs-assets/js/holder.js"></script>
  </body>
</html>
